{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b685787e",
   "metadata": {},
   "source": [
    "Fetch info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a2117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% function - deps - fetch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# current_dir = os.path.dirname(__file__) # for py file\n",
    "current_dir = os.getcwd() # for ipynb file\n",
    "dep_dir = os.path.join(current_dir, 'deps')\n",
    "sys.path.append(dep_dir)\n",
    "\n",
    "from help_func_fetch import Classyfire_Fetcher, PubChem_Fetcher, _get_list_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c179f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load data\n",
    "import pandas as pd\n",
    "\n",
    "raw_df = pd.read_csv('data.csv',header=None,names=['inchikey','smiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7118f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% fetch - pubchem\n",
    "\n",
    "# may try several time to fullly cache data\n",
    "# fetch pubchem basic info\n",
    "pbc_f = PubChem_Fetcher(cache_folder = 'refinfo/pubchem', cache_file = 'refinfo/pubchem/pbc_cache.feather')\n",
    "inchikey_list = raw_df['inchikey'].values.tolist()\n",
    "results_basic = pbc_f.fetch_pubchem_basic(inchikey_list, mode = 'inchikey', use_service=True)\n",
    "\n",
    "# fetch pubchem json through REST PUG\n",
    "cid_list = results_basic['cid'].values.tolist()\n",
    "results_json = pbc_f.fetch_pubchem_json(cid_list, mode = 'cid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% fetch - classyfire\n",
    "from help_func_fetch import Classyfire_Fetcher\n",
    "\n",
    "cly_f = Classyfire_Fetcher(cache_file = 'refinfo/classyfire/clf_cache.feather')\n",
    "smi_list = raw_df['smiles'].tolist()\n",
    "results_clf = cly_f.fetch_classfire(smi_list, mode = 'smiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Merge info\n",
    "full_df = pd.merge(raw_df, results_basic[['inchikey', 'cid','casrn', 'dtxsid','iupac_name']], on='inchikey', how='left')\n",
    "full_df = pd.merge(full_df, results_clf[['input', 'kingdom', 'superclass','class', 'subclass','direct_parent',]], left_on='smiles', right_on='input', how='left')\n",
    "full_df = full_df.drop(columns = ['input'])\n",
    "full_df = pd.merge(full_df, results_json.drop(columns = ['cid']), left_on = 'cid', right_on='input', how='left')\n",
    "full_df = full_df.drop(columns = ['input'])\n",
    "print(full_df.head(5))\n",
    "\n",
    "full_df.to_feather('data_full.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f562343e",
   "metadata": {},
   "source": [
    "Calc mol similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c2cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% function - deps - mol simi\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# current_dir = os.path.dirname(__file__) # for py file\n",
    "current_dir = os.getcwd() # for ipynb file\n",
    "dep_dir = os.path.join(current_dir, 'deps')\n",
    "sys.path.append(dep_dir)\n",
    "\n",
    "from help_func_mol import mol_simi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% calc - pairwise, so take long time if too much rows\n",
    "\n",
    "# import pandas as pd\n",
    "# full_df = pd.read_feather('data_full.feather')\n",
    "\n",
    "full_df['mol'] = full_df['smiles'].map(Chem.MolFromSmiles)\n",
    "full_df = full_df[full_df['mol'].notna()].reset_index(drop=True)\n",
    "\n",
    "results_simi = mol_simi_df(full_df, 'mol', n_jobs=-1)\n",
    "# with open('simi.pkl', 'wb') as f:\n",
    "#     pickle.dump(results_simi, f)\n",
    "\n",
    "# with open('simi.pkl', 'rb') as f:\n",
    "#     results_simi = pickle.load(f)\n",
    "\n",
    "simi_weights = [1/3,1/3,1/3]\n",
    "for dict1 in results_simi:\n",
    "    main_simi, core_simi , msc_simi = dict1['simi']\n",
    "    dict1['simi'] = sum([main_simi*simi_weights[0], core_simi*simi_weights[1], msc_simi*simi_weights[2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912ee422",
   "metadata": {},
   "source": [
    "Define food related or synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load data\n",
    "import pandas as pd\n",
    "\n",
    "full_df = pd.read_feather('data_full.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6892cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% initial foodrelated column\n",
    "\n",
    "full_df['foodrelated'] = None\n",
    "\n",
    "synthetic = full_df[['Industry_Uses', 'Consumer_Uses', 'Manufacturing']].notnull().any(axis=1)\n",
    "food_relate = full_df['Associated_Foods'].notnull()  \n",
    "food_safe = full_df['Food_Additive_ADI'].str.contains('No safety concern') & full_df['Food_Additive_ADI'].notnull()\n",
    "\n",
    "full_df.loc[food_relate & ~synthetic, 'foodrelated'] = 'onlyfoodrelate'  \n",
    "full_df.loc[food_relate & synthetic, 'foodrelated'] = 'mixinfo'  \n",
    "full_df.loc[synthetic & ~food_relate, 'foodrelated'] = 'onlysynthetic'\n",
    "full_df.loc[~food_relate & ~synthetic, 'foodrelated'] = 'unknown'  \n",
    "full_df.loc[food_safe, 'foodrelated'] = 'onlyfoodrelate' \n",
    "\n",
    "full_df.drop(['mol'], axis=1).to_feather('data_full_before.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1480393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% info share - foodrelated column fill\n",
    "from tqdm import tqdm\n",
    "\n",
    "similarity_threshold = 0.7\n",
    "\n",
    "results_simi1 = [sim_dict for sim_dict in results_simi if sim_dict['simi'] > similarity_threshold]\n",
    "results_simi1 = pd.DataFrame(results_simi1)\n",
    "\n",
    "modification_log = []\n",
    "\n",
    "n = 0\n",
    "max_run = 40\n",
    "\n",
    "while True:\n",
    "    n += 1\n",
    "    unknown_len = len(full_df[full_df['foodrelated'] == 'unknown'])\n",
    "    change_require = []\n",
    "\n",
    "    for unknown_index in tqdm(full_df[full_df['foodrelated'] == 'unknown'].index, desc = f'Run {n}'):   \n",
    "        similar_indexes = results_simi1[  \n",
    "            (results_simi1['index1'] == unknown_index) | (results_simi1['index2'] == unknown_index)\n",
    "        ]\n",
    "\n",
    "        if len(similar_indexes) > 0:\n",
    "            similar_rows = []\n",
    "\n",
    "            for _ , row in similar_indexes.iterrows():\n",
    "                if row['index1'] == unknown_index:\n",
    "                    index  = row['index2']\n",
    "                else:\n",
    "                    index = row['index1']\n",
    "                    \n",
    "                if full_df.loc[index, 'foodrelated'] != 'unknown':\n",
    "                    similar_rows.append({'index':index, 'simi':row['simi']})\n",
    "\n",
    "            similar_rows = sorted(similar_rows, key=lambda x: x['simi'], reverse=True)\n",
    "            similar_rows = similar_rows[:15]\n",
    "            \n",
    "            if len(similar_rows) > 0:\n",
    "\n",
    "                full_df_simi_index = [row['index'] for row in similar_rows]\n",
    "                full_df_simi_simi = [row['simi'] for row in similar_rows]\n",
    "                similar_attributes = full_df.loc[full_df_simi_index, 'foodrelated'].tolist() \n",
    "                if similar_attributes.count('onlyfoodrelate') > 0:\n",
    "                    if similar_attributes.count('mixinfo') == 0 and similar_attributes.count('onlysynthetic') == 0:  \n",
    "                        old_value = full_df.at[unknown_index, 'foodrelated']\n",
    "                        change_require.append(unknown_index)\n",
    "                        \n",
    "                        modification_log.append({'run':n, 'changed_index':unknown_index, 'changed_due_to_index':full_df_simi_index, 'changed_due_to_simi':full_df_simi_simi, 'old_value': old_value, 'new_value': 'onlyfoodrelate'})\n",
    "        \n",
    "    # print(len(change_require))\n",
    "    full_df.loc[change_require, 'foodrelated'] = 'onlyfoodrelate'\n",
    "\n",
    "    if unknown_len == len(full_df[full_df['foodrelated'] == 'unknown']) and n <= max_run:\n",
    "        print(f'Total runs: {n}')\n",
    "        break\n",
    "\n",
    "full_df.drop(['mol'], axis=1).to_feather(f'data_full_after.feather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e88c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% visualize foodrelated column \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# current_dir = os.path.dirname(__file__) # for py file\n",
    "current_dir = os.getcwd() # for ipynb file\n",
    "dep_dir = os.path.join(current_dir, 'deps')\n",
    "sys.path.append(dep_dir)\n",
    "\n",
    "from help_func_mol import add_stroke, get_mol_image\n",
    "from help_func_network import auto_wrap_text\n",
    "\n",
    "before_df = pd.read_feather('data_full_before.feather')\n",
    "diff = pd.merge(before_df, full_df['foodrelated'], left_index = True, right_index=True, suffixes=('_old', '_new'), how='outer')  \n",
    "different_rows = diff[diff['foodrelated_old'] != diff['foodrelated_new']]  \n",
    "diff = different_rows[before_df.columns.tolist()[:-1] + ['foodrelated_old', 'foodrelated_new']].reset_index(drop=True)\n",
    "\n",
    "n = 8\n",
    "num_rows = (len(diff) + n - 1) // n\n",
    " \n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=n, figsize=(2 * n, 2 * num_rows),dpi = 300)  \n",
    "\n",
    "max_width = 0\n",
    "max_height = 0\n",
    "scale = 2\n",
    "\n",
    "for idx, row in diff.iterrows():  \n",
    "    row_num = idx // n\n",
    "    col_num = idx % n\n",
    "\n",
    "    name = row['iupac_name']\n",
    "    cid = row['cid']\n",
    "    if (cid != cid) or (cid == None):\n",
    "        cid = None\n",
    "    else:\n",
    "        cid = str(int(cid))\n",
    "    inchikey = row['inchikey']\n",
    "    label = [name, f'cid: {cid}', inchikey]\n",
    "    label = [i for i in label if i not in [None,np.nan]]\n",
    "    label = '\\n'.join(label)\n",
    "\n",
    "    mol = Chem.MolFromSmiles(row['smiles'])  \n",
    "    if mol is not None:  \n",
    "        img = np.array(get_mol_image(mol,False,False,False))\n",
    "        img_width, img_height = img.shape[1], img.shape[0]\n",
    "        scaled_width = img_width * scale\n",
    "        scaled_height = img_height * scale\n",
    "        axes[row_num, col_num].imshow(img, extent=(0 - scaled_width / 2, 0 + scaled_width / 2, \n",
    "                                0 - scaled_height / 2, 0 + scaled_height / 2))\n",
    "        \n",
    "        max_width = max(max_width, scaled_width)\n",
    "        max_height = max(max_height, scaled_height)\n",
    "\n",
    "    group_info = f\"{label}\\n{row['foodrelated_old']} -> {row['foodrelated_new']}\"\n",
    "    group_info = auto_wrap_text(group_info) \n",
    "\n",
    "    axes[row_num, col_num].text(0.5, -0.1, group_info, fontsize=4, \n",
    "                                ha='center', va='top', \n",
    "                                transform=axes[row_num, col_num].transAxes\n",
    "                                )    \n",
    "for ax in axes.flatten():\n",
    "    ax.set_xlim(-max_width/2, max_width/2)\n",
    "    ax.set_ylim(-max_height/2, max_height/2)\n",
    "    ax.axis('off')\n",
    "\n",
    "for i in range(len(diff), num_rows * n):  \n",
    "    axes[i // n, i % n].axis('off') \n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0) \n",
    "plt.tight_layout()  \n",
    "fig.savefig('chemchangetofoodrelate.png',bbox_inches='tight', dpi=200, transparent=False) \n",
    "plt.show() \n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83361fc",
   "metadata": {},
   "source": [
    "Ready network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362600c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% function - deps - network plot \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import networkx as nx\n",
    "import math\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# current_dir = os.path.dirname(__file__) # for py file\n",
    "current_dir = os.getcwd() # for ipynb file\n",
    "dep_dir = os.path.join(current_dir, 'deps')\n",
    "sys.path.append(dep_dir)\n",
    "\n",
    "from help_func_mol import add_stroke, get_mol_image\n",
    "from help_func_network import interpolate_color, auto_wrap_text\n",
    "from help_func_network import plot_graph, trim_edge, cal_layout, compute_grid_layout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6b5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load data\n",
    "\n",
    "full_df = pd.read_feather(f'data_full_after.feather')\n",
    "full_df['mol'] = full_df['smiles'].map(Chem.MolFromSmiles)\n",
    "full_df = full_df[full_df['mol'].notna()].reset_index(drop=True)\n",
    "\n",
    "full_df['casrn'] = full_df['casrn'].apply(_get_list_first)\n",
    "full_df['dtxsid'] = full_df['dtxsid'].apply(_get_list_first)\n",
    "\n",
    "import pickle\n",
    "with open('simi.pkl', 'rb') as f:\n",
    "    results_simi = pickle.load(f)\n",
    "\n",
    "simi_weights = [1/3,1/3,1/3]\n",
    "for dict1 in results_simi:\n",
    "    main_simi, core_simi , msc_simi = dict1['simi']\n",
    "    dict1['simi'] = sum([main_simi*simi_weights[0], core_simi*simi_weights[1], msc_simi*simi_weights[2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Build main networkx graph\n",
    "\n",
    "df = full_df[['iupac_name','smiles','cid','inchikey','mol','superclass', 'class', 'subclass', 'direct_parent','casrn','foodrelated']]\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Adding node to network\",leave = False):\n",
    "    \n",
    "    smiles = row['smiles'] if row['smiles'] is not None else ''\n",
    "    name = row['iupac_name'] if row['iupac_name'] is not None else ''\n",
    "    inchikey = row['inchikey'] if row['inchikey'] is not None else ''\n",
    "    foodrelated = row['foodrelated']\n",
    "\n",
    "    cid = row['cid']\n",
    "    if (cid != cid) or (cid == None):\n",
    "        cid = None\n",
    "    else:\n",
    "        cid = f'cid: {str(int(cid))}'\n",
    "\n",
    "    cas = row['casrn']\n",
    "    if (cas != cas) or (cas == None):\n",
    "        cas = None\n",
    "    else:\n",
    "        cas = f'cas: {str(cas)}'\n",
    "\n",
    "    label = [cas, cid, inchikey]\n",
    "    label = [i for i in label if i not in [None,np.nan]]\n",
    "    label = '\\n'.join(label) if len(label) > 0 else ''\n",
    "\n",
    "    G.add_node(str(idx), name=name, smiles = smiles, inchikey=inchikey, label = label, foodrelated = foodrelated)\n",
    "    \n",
    "G.clear_edges()\n",
    "\n",
    "simi_threshold = 0.7\n",
    "\n",
    "for item in tqdm(results_simi, desc='Adding edges', leave=False):\n",
    "    i = item['index1']\n",
    "    j = item['index2']\n",
    "    simi = item['simi']\n",
    "    fraction = (simi - simi_threshold) / (1 - simi_threshold)\n",
    "\n",
    "    if simi <= simi_threshold:\n",
    "        continue\n",
    "    \n",
    "    G.add_edge(str(i), str(j), simi=simi)\n",
    "\n",
    "folder_path = 'network'\n",
    "\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "nx.write_graphml(G, f\"{folder_path}/network1.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% one-time, generate node community list\n",
    "\n",
    "import json\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "from help_func_network import split_by_community, count_bottom_elements, deterministic_subgraph, trim_edge, convert_sets_to_lists\n",
    "from networkx.algorithms import community\n",
    "\n",
    "clusters = list(nx.connected_components(G))\n",
    "clusters = sorted(clusters, key=lambda c: count_bottom_elements(c), reverse=True)\n",
    "\n",
    "node_list = []\n",
    "\n",
    "for c in clusters:\n",
    "    if len(c)>=200:\n",
    "        subG = deterministic_subgraph(G, c)\n",
    "        subG = trim_edge(subG, keep_top_n = True, keep_span_tree = True, simi_threshold=0.7)\n",
    "        \n",
    "        temp_c = split_by_community(subG, sort = True, resolution = 0.3)\n",
    "        node_list.extend(temp_c)\n",
    "\n",
    "        print(f'before: {len(c)}')\n",
    "        len_str = ','.join([str(len(sub)) for sub in temp_c])\n",
    "        print(f'after: {len_str}')\n",
    "    else:\n",
    "        node_list.append(c)\n",
    "\n",
    "node_list = convert_sets_to_lists(node_list)\n",
    "node_list = sorted(node_list, key=lambda c: count_bottom_elements(c), reverse=True)\n",
    "\n",
    "folder_path = 'network'\n",
    "\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "with open(f'{folder_path}/community_group1.json', 'w') as f:\n",
    "    json.dump(node_list, f)\n",
    "\n",
    "print(len(node_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58300e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% one-time, generate pos_list\n",
    "\n",
    "import json\n",
    "\n",
    "folder_path = 'network'\n",
    "\n",
    "with open(f'{folder_path}/community_group1.json', 'r') as f:\n",
    "    node_list = json.load(f)\n",
    "\n",
    "from help_func_network import deterministic_subgraph, trim_edge, cal_layout, count_bottom_elements\n",
    "\n",
    "folder_path = 'network'\n",
    "pos_folder = 'pos'\n",
    "\n",
    "if not os.path.exists(f'{folder_path}/{pos_folder}'):\n",
    "    os.makedirs(f'{folder_path}/{pos_folder}')\n",
    "\n",
    "# pos_list = []\n",
    "for i, c in enumerate(tqdm(node_list)):\n",
    "    subG = deterministic_subgraph(G, c)\n",
    "    subG = trim_edge(subG, keep_top_n = True, keep_span_tree = True, simi_threshold=0.7)\n",
    "    pos = cal_layout(subG)\n",
    "    # pos_list.append(pos)\n",
    "    json.dump(pos, open(f'{folder_path}/{pos_folder}/node_pos{i}.json', 'w'))\n",
    "    \n",
    "file_list = os.listdir(f'{folder_path}/{pos_folder}')\n",
    "pos_list = [json.load(open(f'{folder_path}/{pos_folder}/{file}', 'r')) for file in file_list]\n",
    "\n",
    "pos_list = sorted(pos_list, key=lambda c: len(list(c.keys())), reverse=True)\n",
    "json.dump(pos_list, open(f'{folder_path}/node_pos1.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% trim edge for the main graph\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd() # for ipynb file\n",
    "dep_dir = os.path.join(current_dir, 'deps')\n",
    "sys.path.append(dep_dir)\n",
    "\n",
    "from help_func_network import deterministic_subgraph, trim_edge, convert_sets_to_lists\n",
    "\n",
    "edge_list = []\n",
    "\n",
    "for ns in node_list:\n",
    "    subG = deterministic_subgraph(G,ns)\n",
    "    subG = trim_edge(subG, keep_top_n = True, keep_span_tree = True, simi_threshold=0.7)\n",
    "    edge_list.extend(list(subG.edges(data=True)))\n",
    "    # for u, v, attr in subG.edges():\n",
    "    #     edge_list.append(subG.edges())\n",
    "\n",
    "G.clear_edges()\n",
    "for u, v, attr in edge_list:\n",
    "    G.add_edge(u, v, **attr)\n",
    "\n",
    "nx.write_graphml(G, f\"{folder_path}/network2.graphml\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3863d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% one-time, generate node image\n",
    "\n",
    "import shutil\n",
    "from rdkit import Chem\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# current_dir = os.path.dirname(__file__) # for py file\n",
    "current_dir = os.getcwd() # for ipynb file\n",
    "dep_dir = os.path.join(current_dir, 'deps')\n",
    "sys.path.append(dep_dir)\n",
    "\n",
    "from help_func_mol import get_mol_image\n",
    "\n",
    "def generate_image(G, attr_name, image_dir = \"mol_images\" , keep_exist = False):\n",
    "    '''\n",
    "    Generate molecule images for nodes in a networkx graph and save them to a directory.\n",
    "    '''\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "    else:\n",
    "        if not keep_exist:\n",
    "            shutil.rmtree(image_dir)\n",
    "            os.makedirs(image_dir)\n",
    "\n",
    "    for node, attr in tqdm(G.nodes(data=True), desc='Generating images', leave=False):\n",
    "\n",
    "        smiles = attr.get(attr_name, None)\n",
    "        if smiles is None:\n",
    "            continue\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "        image_path = os.path.join(image_dir, f\"node_{node}.png\")\n",
    "        G.nodes[node]['image'] = image_path\n",
    "        if not os.path.exists(image_path):\n",
    "            mol_img = get_mol_image(mol)\n",
    "            mol_img.save(image_path)\n",
    "\n",
    "folder_path = 'network'\n",
    "generate_image(G,'smiles', image_dir = f'{folder_path}/mol_images', keep_exist = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee237076",
   "metadata": {},
   "source": [
    "Draw network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% function - deps - network plot \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import math\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# current_dir = os.path.dirname(__file__) # for py file\n",
    "current_dir = os.getcwd() # for ipynb file\n",
    "dep_dir = os.path.join(current_dir, 'deps')\n",
    "sys.path.append(dep_dir)\n",
    "\n",
    "from help_func_network import interpolate_color, plot_graph, trim_edge, compute_grid_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load node list, pos list\n",
    "import json\n",
    "import networkx as nx\n",
    "\n",
    "folder_path = 'network'\n",
    "\n",
    "with open(f'{folder_path}/community_group1.json', 'r') as f:\n",
    "    node_list = json.load(f)\n",
    "\n",
    "with open(f'{folder_path}/node_pos1.json', 'r') as f:\n",
    "    pos_list = json.load(f)\n",
    "\n",
    "G = nx.read_graphml(f\"{folder_path}/network2.graphml\")\n",
    "image_dir = f'{folder_path}/mol_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae28f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% color for foodrelated and simi\n",
    "\n",
    "node_color_palette = {\n",
    "    'onlyfoodrelate' : 'green',\n",
    "    'onlysynthetic': 'red',\n",
    "    'mixinfo' : 'blue',\n",
    "    'unknown': 'grey',\n",
    "    '-1': 'grey',\n",
    "}\n",
    "\n",
    "for node, data in G.nodes(data=True):\n",
    "    color_key = data.get('foodrelated', None)\n",
    "    color = node_color_palette.get('-1', 'grey')\n",
    "    if node_color_palette.get(color_key, None):\n",
    "        color = node_color_palette[color_key]\n",
    "    G.nodes[node]['color'] = color\n",
    "    image_path = os.path.join(image_dir, f\"node_{node}.png\")\n",
    "    G.nodes[node]['image'] = image_path\n",
    "\n",
    "simi_threshold = 0.7\n",
    "start_color = \"#b3b3b3\"      # Color at threshold (lighter)\n",
    "end_color = \"#000000\"        # Color at sim=1 (darker)\n",
    "\n",
    "for i, j, data in G.edges(data=True):\n",
    "    simi = data['simi']\n",
    "    fraction = (simi - simi_threshold) / (1 - simi_threshold)\n",
    "    edge_color = interpolate_color(start_color, end_color, fraction)\n",
    "    G.edges[i, j]['color'] = edge_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d39b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% calc fig size\n",
    "import math\n",
    "\n",
    "clusters = sorted(pos_list, key=lambda c: len(c), reverse=True)\n",
    "\n",
    "group1 = [c for c in clusters if len(c) > 7] # each large cluster get their own fig\n",
    "group2 = [c for c in clusters if 3 <= len(c) <= 7] # small cluster all in one grid fig\n",
    "group3 = [c for c in clusters if len(c) <= 2] # pair and single point in one grid fig\n",
    "\n",
    "f_sizes = []\n",
    "for cluster in group1:\n",
    "    n_count = len(cluster)\n",
    "    c_size = math.ceil(math.sqrt(n_count))\n",
    "    # c_size = math.sqrt(n_count)\n",
    "    f_sizes.append([c_size,c_size])\n",
    "\n",
    "c_count = len(group2)\n",
    "sub_f_row = math.ceil(math.sqrt(c_count))\n",
    "n_count = 7\n",
    "# c_size = math.ceil(math.sqrt(n_count)\n",
    "c_size = math.sqrt(n_count)\n",
    "f_sizes.append([c_size*sub_f_row,c_size*sub_f_row])\n",
    "\n",
    "n_count = len([node for cluster in group3 for node in cluster])\n",
    "c_size = math.ceil(math.sqrt(n_count))\n",
    "f_sizes.append([c_size,c_size])\n",
    "\n",
    "pix_multi = 1000\n",
    "f_sizes = [[int(pix_multi*w),int(pix_multi*h)] for w,h in f_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c40b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%  sepe plot for each community\n",
    "import json\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import re\n",
    "\n",
    "pix_multi = 1000\n",
    "f_sizes_n = 0\n",
    "simi_threshold=0.7\n",
    "dpi = 200\n",
    "\n",
    "draw_outer_border = True\n",
    "draw_subplot_inter_border = True\n",
    "\n",
    "folder_path = 'network/'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# network custom setting\n",
    "node_image = True\n",
    "node_halo = True\n",
    "node_halo_radius = 100\n",
    "\n",
    "node_label = True\n",
    "edge_color = True\n",
    "edge_label = True\n",
    "image_stroke = True\n",
    "ax_border = False\n",
    "\n",
    "for i, pos_list in enumerate(tqdm(group1, leave = False)):\n",
    "    \n",
    "    node_list = pos_list.keys()\n",
    "    f_size_w = f_sizes[f_sizes_n][0]\n",
    "    f_size_h = f_sizes[f_sizes_n][1]\n",
    "\n",
    "    subG = G.subgraph(node_list).copy()\n",
    "    prunedG = trim_edge(subG, simi_threshold=simi_threshold)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(f_size_w/dpi, f_size_h/dpi), dpi=dpi)\n",
    "\n",
    "    plot_graph(ax, pos_list, prunedG, \n",
    "               node_image=node_image, node_label=node_label, \n",
    "               node_image_stroke=image_stroke, \n",
    "               node_halo = node_halo, node_halo_radius = node_halo_radius,\n",
    "               edge_color=edge_color, edge_label=edge_label, \n",
    "               ax_border=ax_border)\n",
    "    plt.tight_layout()\n",
    "    # ax.set_aspect('equal')\n",
    "\n",
    "    if draw_outer_border:\n",
    "        global_rect = plt.Rectangle((0, 0), 1, 1,fill=False, edgecolor='black', linewidth=2,transform=fig.transFigure, zorder=5)\n",
    "        fig.add_artist(global_rect)\n",
    "        \n",
    "    fig.savefig(f'{folder_path}/fig_{f_sizes_n:02d}.png', transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    f_sizes_n += 1\n",
    "\n",
    "if group2:\n",
    "\n",
    "    f_size_w = f_sizes[f_sizes_n][0]\n",
    "    f_size_h = f_sizes[f_sizes_n][1]\n",
    "\n",
    "    n_plots = len(group2)\n",
    "    n_rows = math.ceil(math.sqrt(n_plots))\n",
    "    n_cols = math.ceil(n_plots / n_rows)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(f_size_w/dpi, f_size_h/dpi), dpi=dpi)\n",
    "    axes = axes.flatten() if n_plots > 1 else [axes]\n",
    "\n",
    "    for i, pos_list in enumerate(tqdm(group2, leave = False)):\n",
    "        \n",
    "        node_list = pos_list.keys()\n",
    "        node_count = len(node_list)\n",
    "        size = math.ceil(math.sqrt(node_count))\n",
    "        subG = G.subgraph(node_list).copy()\n",
    "        prunedG = trim_edge(subG, simi_threshold=simi_threshold)\n",
    "\n",
    "        plot_graph(axes[i], pos_list, prunedG, \n",
    "               node_image=node_image, node_label=node_label, \n",
    "               node_image_stroke=image_stroke,\n",
    "               node_halo = node_halo, node_halo_radius = node_halo_radius,\n",
    "               edge_color=edge_color, edge_label=edge_label, \n",
    "               )\n",
    "        \n",
    "        # axes[i].set_aspect('equal')\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if draw_subplot_inter_border:\n",
    "        for ax in fig.axes:\n",
    "            ss = ax.get_subplotspec()\n",
    "            i, j = ss.rowspan.start, ss.colspan.start\n",
    "            \n",
    "            left = j / n_cols\n",
    "            bottom = (n_rows - i - 1) / n_rows\n",
    "            width = 1 / n_cols\n",
    "            height = 1 / n_rows\n",
    "            \n",
    "            rect = plt.Rectangle((left, bottom), width, height, fill=False, edgecolor='black', linewidth=2, transform=fig.transFigure, zorder=5)\n",
    "            fig.add_artist(rect)\n",
    "\n",
    "    if draw_outer_border:\n",
    "        global_rect = plt.Rectangle((0, 0), 1, 1,fill=False, edgecolor='black', linewidth=2,transform=fig.transFigure, zorder=5)\n",
    "        fig.add_artist(global_rect)\n",
    "\n",
    "    fig.savefig(f'{folder_path}fig_{f_sizes_n:02d}.png', transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    f_sizes_n += 1\n",
    "\n",
    "if group3:\n",
    "\n",
    "    f_size_w = f_sizes[f_sizes_n][0]\n",
    "    f_size_h = f_sizes[f_sizes_n][1]\n",
    "\n",
    "    group3_nodes = [node for cluster in group3 for node in cluster.keys()]\n",
    "\n",
    "    subG3 = G.subgraph(group3_nodes)\n",
    "    fig, ax = plt.subplots(figsize=(f_size_w/dpi, f_size_h/dpi), dpi=dpi)\n",
    "\n",
    "    pos = compute_grid_layout(group3_nodes, dist=len(group3_nodes)/4)\n",
    "    plot_graph(ax, pos, subG3, \n",
    "               node_image=node_image, node_label=node_label, \n",
    "               node_image_stroke=image_stroke,\n",
    "               node_halo = node_halo, node_halo_radius = node_halo_radius,\n",
    "               edge_color=edge_color, edge_label=edge_label, \n",
    "               )\n",
    "    plt.tight_layout()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    if draw_outer_border:\n",
    "        global_rect = plt.Rectangle((0, 0), 1, 1,fill=False, edgecolor='black', linewidth=2, transform=fig.transFigure, zorder=5)\n",
    "        fig.add_artist(global_rect)\n",
    "\n",
    "    fig.savefig(f'{folder_path}fig_{f_sizes_n:02d}.png', transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    f_sizes_n += 1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
